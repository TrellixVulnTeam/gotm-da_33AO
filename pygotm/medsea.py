from .config import project_folder, GOTM_executable, GOTM_nml_path, GOTM_nml_list, project_name, GOTM_version, epoch
from .gotmks import *

import numpy as np

## Settings and initializations for medsea runs.

# If a change to the following is desired, do so right after loading the module and then call set_grid() and set_folders() in this order.
ASM = 3 # This selects the GOTM extra parameters profile
max_depth = 75
nlev = 122 # Number of levels in the truncated grid for up to 75m.
grid = '144x'

## TODO This should be generated by the choice of ASM, max_depth and also GOTM executable version.
# This will also be in the name (as a suffix before the .nc extension) in the nc file per grid point.
run = 'ASM3-75m' # Will be reset when set_grid() is called.

## TODO The region and horizontal grid level (1x) and vertical grid level (122) should be includede in the run tag?
region = 'medsea' # practically just a prefix of filenames for now, the code is strongly tied to this assumption

# A switch.
overwrite = True # True means running at the same grid point will overwrite files if already present (notably the *.inp etc...)

# Routines to set global values in this module. Can be used in interactive session to change config.

def set_grid(new_grid=grid,
             new_max_depth=max_depth, # These names just need to be different... Because we cannot declare an input name global below...
             subindices=None,
             plot = False, stat = False,
             ):
    """ Obtain the 1/16 degree grid used in medsea_rea, and classify each grid points according to 'max_depth'.
        A sub-grid is set to the global variables in the module, and also returned by specifying 'subindices':
            ** 9x test grid (the only one with both lat and lon being multiples of 0.25):
                    subindices=(slice(1,None,4), slice(0,None,4))
            ** 9x grids (16 of them, including the 9x test grid above):
                    subindices=(slice(i,None,4), slice(j,None,4))
               for (i,j) in {0,1,2,3} x {0,1,2,3}
            ** 1x grid that is co-locational with ERA data grid:
                    subindices=(slice(9,None,12), slice(None,None,12))
            ** a mini grid with only 23 sea locations with depth >= 75 that can be used for testing:
                    subindices=(slice(1,None,48), slice(None,None,48))
               NOTE: In medsea_ERA dataset, the latitudes are arranged, exceptionally, in descending order.

       Returns three tuples:
            subgrid = (grid_lats, grid_lons, medsea_flags, max_depth)
            rea_indices = (medsea_rea_lat_ind, medsea_rea_lon_ind, medsea_rea_ndepth)
            grid_indices = (M, N, sea_mn, sea_m, sea_n)
    """
    print('Initializing grid...')
    # Declaring global is necessary for modifying them interactively after importing this module.
    global run, grid, max_depth, ASM
    global grid_lats, grid_lons, medsea_flags, max_depth
    global medsea_rea_lat_ind, medsea_rea_lon_ind, medsea_rea_ndepth
    global M, N, sea_mn, sea_m, sea_n

    # Override the global variables using values passed from function call.
    grid = new_grid
    max_depth = new_max_depth

    # Update the run name
    run = 'ASM{:d}-{:d}m'.format(ASM,max_depth)

    # Set up the slices for the subgrid using the name.
    if new_grid in ['9x_{:d}'.format(i) for i in range(16)]:
        k = int(new_grid[3:])
        #print('k=',k)
        if subindices is not None:
            raise Exception("Mistakes? 'subindices' need not be given if a known 'grid' is provided.")
        else:
            i = int(k/4)
            j = k%4
            subindices = (slice(i,None,4), slice(j,None,4))

    if new_grid == 'aeg_144x':
        subindices = (slice(77,186,None), slice(456,553,None))

    if new_grid == 'aeg_36x':
        subindices = (slice(77,186,2), slice(456,553,2))
        
    if new_grid == 'aeg_9x':
        subindices = (slice(77,186,4), slice(456,553,4))
    
    if new_grid == '144x':
        subindices = (slice(None,None,None),slice(None,None,None))

    # 2017-10-24
    if new_grid == '36x':
        subindices = (slice(None,None,2), slice(None,None,2))

    if new_grid == '1x':
        subindices = (slice(9,None,12), slice(None,None,12))

    if new_grid == 'mini':
        subindices=(slice(1,None,48), slice(None,None,48))

    medsea_rea_lat_ind = subindices[0]
    medsea_rea_lon_ind = subindices[1]
    #print(medsea_rea_lat_ind)
    #print(medsea_rea_lon_ind)

    # Load the rea grid, and a sample set of data for its masks.
    with Dataset(os.path.join(p_sossta_folder, 'medsea_rea/2013/20130101_TEMP_re-fv6.nc'),'r') as ds:
        lat_rea = ds['lat'][:]
        lon_rea = ds['lon'][:]
        temp_rea = ds['votemper'][:]
        depth_rea = ds['depth'][:]

    # Without the 'safety' of adding one more level, we can get more grid points...
    #medsea_rea_ndepth = sum(depth_rea<max_depth)

    medsea_rea_ndepth = sum(depth_rea<max_depth)+1

    # 2 means deeper than max_depth, 1 means less than max_depth, 0 means land
    loc_type = 0 + ~temp_rea[0,0,:].mask + ~temp_rea[0,medsea_rea_ndepth,:].mask

    # Setting values to global names.
    grid_lats = lat_rea[subindices[0]]
    grid_lons = lon_rea[subindices[1]]
    medsea_flags = loc_type[subindices[0],subindices[1]]
    #print(grid_lats,grid_lons)
    assert grid_lats.shape, grid_lons.shape == medsea_flags.shape

    M, N = medsea_flags.shape
    assert M == grid_lats.size and N == grid_lons.size

    sea_m, sea_n = np.where(medsea_flags==2)
    sea_mn = [(sea_m[i],sea_n[i]) for i in range(sea_m.size)]
    assert len(sea_mn) == sea_m.size

    #print(grid_lats.size,grid_lons.size,grid_lats.min(),grid_lats.max(),grid_lons.min(),grid_lons.max())
    print('Finished setting up a subgrid of shape {!s} x {!s} with {!s} <= latitude <= {!s}, {!s} <= longitude <= {!s}.'.format(\
            grid_lats.size,grid_lons.size,grid_lats.min(),grid_lats.max(),grid_lons.min(),grid_lons.max()))
    if stat:
        # The following are for the current subgrid.
        def print_stat(bl_array):
            drei = bl_array.size
            zwei = (bl_array == 2).sum()
            ein = (bl_array == 1).sum()
            null = (bl_array == 0).sum()
            assert null+ein+zwei == drei
            print('\t' + 'sea (>{!s}m) locations: {!s}'.format(max_depth,zwei) + ', {:4.2f}% out of {!s}'.format(zwei*100/drei,drei))
            print('\t' + 'sea (<{!s}m) locations: {!s}'.format(max_depth,ein) + ', {:4.2f}% out of {!s}'.format(ein*100/drei,drei))
            print('\t' + 'land locations: {!s}'.format(null) + ', {:4.2f}% out of {!s}'.format(null*100/drei,drei))

        print('In the current grid:')
        print_stat(medsea_flags)
        print('In the full medsea_rea grid:')
        print_stat(loc_type)

    if plot:
        import matplotlib.pyplot as plt
        fig, axes = plt.subplots(2,1,figsize=(14,14))
        ax1, ax2 = axes
        ax1.imshow(loc_type,origin='lower',extent=[lon_rea.min(),lon_rea.max(),lat_rea.min(),lat_rea.max()],cmap=cm.Blues)
        ax1.set_title('full medsea_rea grid')
        ax2.imshow(medsea_flags,origin='lower',extent=[lon_rea.min(),lon_rea.max(),lat_rea.min(),lat_rea.max()],cmap=cm.Blues)
        ax2.set_title('current subgrid')
        for ax in axes:
            ax.set_xlabel('longitude')
            ax.set_ylabel('latitude')

    # These values have been written directly to global variables as well.
    subgrid = (grid_lats, grid_lons, medsea_flags, max_depth)
    rea_indices = (medsea_rea_lat_ind, medsea_rea_lon_ind, medsea_rea_ndepth)
    grid_indices = (M, N, sea_mn, sea_m, sea_n)
    return subgrid, rea_indices, grid_indices

def get_grid():
    """
    A simple getter for the global variables, returning three tuples.

    subgrid = (grid_lats, grid_lons, medsea_flags, max_depth)
    rea_indices = (medsea_rea_lat_ind, medsea_rea_lon_ind, medsea_rea_ndepth)
    grid_indices = (M, N, sea_mn, sea_m, sea_n)
    """

    global grid_lats, grid_lons, medsea_flags, max_depth
    global medsea_rea_lat_ind, medsea_rea_lon_ind, medsea_rea_ndepth
    global M, N, sea_mn, sea_m, sea_n
    return (grid_lats, grid_lons, medsea_flags, max_depth), \
        (medsea_rea_lat_ind, medsea_rea_lon_ind, medsea_rea_ndepth), \
        (M, N, sea_mn, sea_m, sea_n)

# Set default global values at the loading of this module.

# For the grid info. Load from the file if it exists.
if not(os.path.isfile(os.path.join(project_folder,'medsea_grid_data.npy'))):
    subgrid_data = set_grid()
    np.save(os.path.join(project_folder,'medsea_grid_data.npy'),subgrid_data)
else:
    subgrid, rea_indices, grid_indices = np.load(os.path.join(project_folder,'medsea_grid_data.npy'))
    grid_lats, grid_lons, medsea_flags, max_depth = subgrid
    medsea_rea_lat_ind, medsea_rea_lon_ind, medsea_rea_ndepth = rea_indices
    M, N, sea_mn, sea_m, sea_n = grid_indices

# GOTM dat files' netCDF reformatted dataset sources.
def data_sources(year=None, month=None, mode='r', region='medsea',
                 dat=['heat','met','tprof','sprof','chlo','iop']):
    """
    Return the netCDF4 Dataset (or MFDataset) handles for the data source.
    Omitting month returns yearly data, omitting both year and month returns
    all available data.

    The dataset returns in read-only mode.

    """
    from netCDF4 import Dataset, MFDataset
    import os

    if (year is None) or (month is None):
        MF = True
        # Need to use MFDataset
        NCDataset = MFDataset
    else:
        # When both year and month is given, we can specifically return handle to our reformatted datasets
        # organized by months.
        NCDataset = Dataset

    if isinstance(dat,str):
        # if only one type is requested, still make it into a list so that list comprehension still works.
        dat = [dat]

    # nc_dict = dict(heat = MFDataset(os.path.join(data_folder,'medsea_ERA-INTERIM','medsea_ERA_*.nc')),
    #                met = MFDataset(os.path.join(data_folder,'medsea_ERA-INTERIM','medsea_ERA_*.nc')),
    #                tprof = MFDataset(os.path.join(data_folder,'medsea_rea','medsea_rea_votemper_*.nc')),
    #                sprof = MFDataset(os.path.join(data_folder,'medsea_rea','medsea_rea_vosaline_*.nc')))

    def src(name):
        "Data source name for each 'name'.dat file."
        assert isinstance(name,str)

        if name == 'heat' or name == 'met':
            return 'ERA'
        elif name == 'tprof' or name == 'sprof':
            return 'rea'
        elif name == 'chlo' or name == 'iop':
            return 'MODIS'
        else:
            raise NotImplementedError('Data source unknown for ' + name)
        return None

    def fullfn(name, subfolder=None):
        '''
        Return full absolute path to the nc file. Specify a subfolder for
        flexility of referring to different versions of the datasets.
        '''
        folder = os.path.join(data_folder, region + '_' + src(name))

        # Building the suffix that decreases the time range of coverage, use
        # wildcards if necessary.
        if year is not None:
            if month is None:
                # Both *_2013.nc and *_201301.nc through *201312.nc will be
                # caught be this pattern. Be careful in the folder content.
                suffix = '_{:d}*.nc'.format(year)
            else:
                suffix = '_{:d}{:02d}.nc'.format(year,month)
        else: # So, 'year' is None
            assert month is None
            # Hopefully, the time units of each nc file in the folder has
            # the same unit and epoch, so that MFDataset opens them properly.
            suffix = '_*.nc'

        fn = region + '_' + src(name) + '_' + name + suffix

        if subfolder:
            fn = os.path.join(subfolder,fn)

        return os.path.join(folder,fn)

    # Building up the dictionary to map the appropriate filenames.
    fn_dict = {name: fullfn(name) for name in dat}

    # Now we atta
    for each in fn_dict.keys():
        try:
            ds_dict = {each : NCDataset(fn_dict[each],mode) for each in dat}
        except OSError:
            print('Error accessing {:s}.'.format(fn_dict[each]))
            raise
        except:
            print('Error accessing {:s}.'.format(fn_dict[each]))
            print('Requested list of dat files: {!s}.'.format(dat))
            print('Available built-in data sources: {!s}.'.format(fn_dict))
            raise

    if len(ds_dict.keys()) == 1:
        # If only one dataset requested, return the netcdf dataset unwrapped.
        return ds_dict[dat[0]]
    else:
        # Else return a dictionary of datasets.
        return ds_dict

## Helper functions
def timestr(nctime,i):
    " Return a formatted time string from a nc time variable at index i."
    from netCDF4 import datetime, num2date
    try:
        ts = datetime.strftime(num2date(nctime[i],nctime.units),'%Y-%m-%d %H:%M:%S')
    except:
        print("Converting datetime to string failed!")
        print('i,len(nctime),nctime[i],nctime.units')
        print(i,len(nctime),nctime[i],nctime.units)
        raise
    return ts

def print_lat_lon(lat,lon,fmt_str='g'):
    "Helper function for printing (lat,lon) as 10.5N2.1E etc. "

    # if not(isinstance(lat,float)):
    #     raise Exception("`lat` is of type " + str(type(lat)))
    # if not(isinstance(lon,float)):
    #     raise Exception("`lon` is of type " + str(type(lon)))
    lat = float(lat)
    lon = float(lon)

    template = '{:' + fmt_str + '}'
    lat_str = template.format(lat) + 'N' if lat>=0 else template.format(-lat) + 'S'
    lon_str = template.format(lon) + 'E' if lon>=0 else template.format(-lon) + 'W'
    #return lat_str + ' ' + lon_str
    return lat_str + lon_str

def chunk(c,k,fun,*args,**kwargs):
    """
    calls fun() for the c-th chunk with k grid points (c-1)*10, (c-1)*10+1, ... (c-1)*10+9.
    This partitions the 390 grid points on sea into 30 chunks.
    """

def get_m_n(lat,lon):
    "Return the grid index (m,n) given latlong. Assume uniformly-spaced grid."
    spacing = grid_lats[1]-grid_lats[0]
    m = (lat-grid_lats[0])/spacing
    n = (lon-grid_lons[0])/spacing
    if m%1 != 0. or n%1 != 0.:
        print('Warning: given latlong ({!s},{!s}) does not correspond exactly to a point in the {:s} grid.'.format(lat,lon,grid))
        m = int(round(m))
        n = int(round(n))
        print('Returning the indices to the closest grid point instead: ({!s},{!s}).'.format(grid_lats[m],grid_lons[n]))
    return int(m), int(n)

def get_lat_lon(m,n):
    "Return the latlong given the grid index (m,n)."
    return grid_lats[m],grid_lons[n]

## Medsea serial / parallel run toolbox
def get_local_folder(*args, new_lats=None,new_lons=None,create=False):
    """
    Return the corresponding local folder for given grid point indices (m,n) or linear index i of the
    index arrays sea_m and sea_n.

    Defaults to the run_folder set by the module 'run' global variable, and 'run_folder' generated by
    set_folders(). If not desired, pass a new_run keyword argument to get a different run's local folder.

    TODO: It will be convenient that this function be overloaded by argument type and number (single/multiple
    dispatch). We want get_local_folder(i) and get_local_folder(m,n) or get_local_folder((m,n)) to both work.
    Oh well, that's an overkill. Just use *args and count the number for now, that single dispatch thing is
    better if we need to distinguish by the type of argument.
    """
    ## Setting default argument values.

    # use module defaults if not provided:
    if new_lats is None:
        new_lats = grid_lats
    if new_lons is None:
        new_lons = grid_lons

    if args is None:
        print('No grid indices given, defaulting to the favourite grid point (lat, lon) = (36.00, 25.50) near buoy 61277...')
        m, n = get_m_n(36.,25.5)
        print('m =',m,'n =',n)
    elif len(args) == 1:
        i = args[0]
        assert isinstance(i,int), str(i)
        m = sea_m[i]
        n = sea_n[i]
        print('Using linear index of sea locations, i = {!s}, (m,n) = ({!s},{!s})...'.format(i,m,n))
    elif len(args) == 2:
        m,n = args
        if not(int(m) == m and int(n) == n):
            raise Exception('Given (m, n) = ({!s}, {!s}) do not seem to be grid indices.'.format(m,n))
    else:
        print('Position arguments given: ', args)
        raise Exception('Wrong number of positional arguments given.')

    ## Set up local variables
    lat  = new_lats[m]
    lon = new_lons[n]
    latlong = print_lat_lon(lat,lon)
    local_folder = os.path.join(base_folder,latlong)

    if not(os.path.isdir(local_folder)):
        if create:
            print('The folder {:s} is not found, creating it.'.format(local_folder))
            os.mkdir(local_folder)
        else:
            raise IOError("The local folder {:s} is not found. Have you run local_dat()?".format(local_folder))
    return local_folder

def local_dat(mm,nn,dat=['heat','met','tprof','sprof','chlo','iop']):
    """
    Generate *.dat files from all available data. See core_dat() for other explanations.
    mm, nn can be a sequence of m,n's
    """

    from netCDF4 import MFDataset
    from tempfile import mkdtemp
    from shutil import copyfile
    from glob import glob

    if isinstance(dat,str):
        dat = [dat]

# 20170621, we no longer create separate folders for different runs, but share the same set of subfolders named
# by print_lat_lon(), to avoid creating too many files and draining disk quota too fast.
#    run_folder = os.path.join(base_folder,run)
    run_folder = base_folder

#    if not(os.path.isdir(run_folder)):
#        os.mkdir(run_folder)

    print("Looking for data sources from " + data_folder + "...")
    nc_dict = data_sources(dat=dat)
    if not(isinstance(nc_dict, dict)):
        nc_dict = {dat[0]: nc_dict}
    print(nc_dict)

    for dat_fn, nc in nc_dict.items():
        ## Assume m, n are iterable and of the same length:
        if isinstance(mm,int) and isinstance(nn,int):
            mm = [mm]
            nn = [nn]
        else:
            assert len(m) == len(n)
        try:
            for m, n in zip(mm, nn):
                lat = grid_lats[m]
                lon = grid_lons[n]

                # Create the local folder if necessary.
                local_folder = os.path.join(run_folder,print_lat_lon(lat,lon))
                if not(os.path.isdir(local_folder)):
                    os.mkdir(local_folder)

                # Actually write.
                write_dat(m,n,dat_fn,nc,local_folder)
        except Exception:
                print('mm',mm)
                print('nn',nn)

        ## When m,n are integers, exception occurs at zip() instead, and it not a TypeError.
        # except TypeError as te:
        #     if isinstance(mm,int) and isinstance(nn,int):
        #         m = mm
        #         n = nn
        #         # So the provided sequences are just a single pair of indices. Just write.
        #         write_dat(m,n,dat_fn,nc,local_folder)
        #    else:

#        write_dat(m,n,dat_fn,nc,local_folder)

    for nc in nc_dict.values():
        nc.close()

def prepare_run(start,stop,run_folder,out_dir='.',out_fn='results',m=None,n=None,lat=None,lon=None, **gotm_user_args):
    "Transfer config files and GOTM executable to the folder in which GOTM will be run."
    import shutil
    # Determine the grid point location.
    if (m is None) and (n is None):
        (m,n) = get_m_n(lat,lon)
    if (lat is None) and (lon is None):
        (lat,lon) = get_lat_lon(m,n)
    assert not(m is None or n is None or lat is None or lon is None), 'Either a (m,n) or (lat,lon) should be specified.'

    run_name = 'medsea_GOTM, {:s} grid, #(m,n)=({:d},{:d})'.format(grid,m,n)

    # Set up GOTM arguments.
    gotm_args = dict(name = run_name,
                     start = str(start), stop = str(stop),
                     latitude = float(lat), longitude = float(lon),
                     out_dir = str(out_dir), out_fn = out_fn)
    gotm_args.update(**gotm_user_args)

    # Get the externally specified sea level widths if method is 2.
    if 'grid_method' in gotm_user_args.keys() and gotm_user_args['grid_method'] == 2:
        assert 'grid_file' in gotm_user_args.keys()
        grid_file = gotm_user_args['grid_file']

    # Copy over GOTM executable and config files, the latter to be updated when gotm() is called.
    if not(os.path.exists(GOTM_executable)):
        os.symlink(GOTM_executable,os.path.join(folder,'gotm'))
    for each in GOTM_nml_list:
        # All config files are overwritten every time GOTM is run.
        src = os.path.join(GOTM_nml_path,each)
        dst = os.path.join(run_folder,each)
        # print('Copying {:s} to {:s}'.format(src,dst))
        shutil.copyfile(src,dst)

    # Temporary hack. Also copy the grid data file.
    src = os.path.join(GOTM_nml_path,grid_file)
    dst = os.path.join(run_folder,grid_file)
    # print('Copying {:s} to {:s}'.format(src,dst))
    shutil.copyfile(src,dst)

    # Check that the dat files exists and are of nonzero size.

    # Create a list of dat files we expect to see.
    dat_list = ['tprof','sprof','heat','met']
    if ('t_prof_method' in gotm_user_args):
        tm = gotm_user_args['t_prof_method']
        if tm != 2: # 2 indicates read from file.
            dat_list.remove('tprof')
    if ('s_prof_method' in gotm_user_args):
        sm = gotm_user_args['s_prof_method']
        if sm != 2: # 2 indicates read from file.
            dat_list.remove('sprof')
    if ('extinct_method' in gotm_user_args):
        em = gotm_user_args['extinct_method']
        if em == 9:
            pass
        elif em == 12:
            dat_list.append('chlo')
        elif em == 13:
            dat_list.append('iop')
        else:
            raise NotImplementedError('Not implemented for extinct_method={:d} yet.'.format(em))

    # Now whether each dat file exists and has nonzero size (not just 'touched' by an erroneous read by GOTM)
    for each in dat_list:
        datfn = os.path.join(run_folder,each+'.dat')
        try:
            assert os.path.getsize(datfn) > 0
        except:
            print('{:s} is not found or of size 0, regenerating...'.format(datfn))
            local_dat(m,n,dat=each)
            try:
                assert os.path.getsize(datfn) > 0
            except:
                print('{:s} regeneration failed.'.format(datfn))
                raise

    updatecfg(path=run_folder, **gotm_args)
    return gotm_args

def local_run(year,month,m,n,run,start=None,stop=None,create=False,verbose=False,plotvars=None,**gotm_user_args):
    """

    Generate GOTM results for the (m,n)-th grid point at the specified month. Only *.dat files are expected to be
    in the local folder. The config file, GOTM run time will be generated or copied over.

    Temporary hack: pass None to month to run for the whole year.

    """
    from datetime import datetime
    from netCDF4 import Dataset, num2date
    import shutil
    from os.path import join

    lat, lon = get_lat_lon(m,n)
#    local_folder = get_local_folder(lat,lon,run)
    local_folder = get_local_folder(m,n,create=create)

    # Argument handling, at tht end 'start', 'stop', 'suffix' should all be defined.
    if year is not None:
        if month is None: # Run for a year.
            start = datetime(year,1,1)
            stop = datetime(year,12,31) # Avoid data boundary for now.
            #stop = datetime(year+1,1,1)
            suffix = '_' + run + '_' + '{:04d}'.format(start.year)
        else: # Run for a month
            assert start is None
            assert stop is None
            start = datetime(year,month,1);
            stop = datetime(year,month+1,1) if month < 12 else datetime(year,12,31) # Avoid data boundary for now
            #stop = datetime(year,month+1,1) if month < 12 else datetime(year+1,1,1)
            suffix = '_' + run + '_' + '{:04d}{:02d}'.format(start.year, start.month)
    else: # Run for a specific period.
        assert start is not None
        assert stop is not None

        def check(string):
            if isinstance(string,str):
                assert len(string) == 4+3+3+ 3+3+3 # 2013-01-01 00:00:00
            else:
                assert isinstance(string, datetime)
        check(start)
        check(stop)
        startdayofyear = (start-datetime(start.year-1,12,31)).days # E.g. start is 2013-01-07, then it is 7.
        stopdayofyear = (stop-datetime(stop.year-1,12,31)).days # E.g. stop is 2013-12-31, then it is 365, if stop is 2014-01-01, then it is 1.
        suffix = '_{:04d}{:03d}{:04d}{:03d}_'.format(start.year,startdayofyear,stop.year,stopdayofyear) + run

    # Now we can set the filename in each grid point subfolder.
    out_fn = 'results' + suffix

    # Check global name cache_folder is set of not.
    out_dir = local_folder if cache_folder is None else cache_folder

    if run in run_profiles.keys():
        # Should subclass an Exception to tell people what happened.
        if gotm_user_args != {}:
            print(('{:s} = {!s}' * len(gotm_user_args)).format(*(gotm_user_args.items())))
            raise Exception("A recorded run profile {:s} is specified, rejecting all user arguments for GOTM.\n")
        print('Using pre-defined profile: {:s}...'.format(run))
        gotm_args = prepare_run(start,stop,local_folder,lat=lat,lon=lon,
                                out_fn=out_fn,
                                out_dir=out_dir,
                                daily_stat_fn='daily_stat'+suffix+'.dat',
                                **run_profiles[run])
    else:
        print('Running without a pre-defined profile and creating new folder structures for {:s}...'.format(run))
        gotm_args = prepare_run(start,stop,local_folder,lat=lat,lon=lon,
                                out_dir=out_dir,
                                out_fn=out_fn,
                                daily_stat_fn='daily_stat'+suffix+'.dat',
                                **gotm_user_args)

    os.chdir(local_folder)
    stat = dict()
    try:
        tic()
        logfn = 'GOTM_' + print_ctime(sep='_') + '.log'
        print('GOTM running... ')
        print('  Working from: {:s}...'.format(local_folder))
        gotm(verbose=verbose,logfn=logfn)
        print('  Results written to {:s}.nc...'.format(os.path.join(out_dir,out_fn)))

        if cache_folder is not None:
            src = os.path.join(out_dir,out_fn+'.nc')
            dst = os.path.join(local_folder,out_fn+'.nc')
            try:
                print('Moving {:s} to {:s}...'.format(src,dst))
                shutil.move(src,dst)
            except:
                raise

        stat['elapsed'] = toc()
        # statfn = 'stat_{:d}{:02d}.dat'.format(year,month)
        statfn = 'run_stat_' + print_ctime(sep='_') + '.log'
        with open(statfn,'w') as f:
            print('Writing diagnostic statistics to {0}...\n'.format(statfn))
            f.write('--------------------------------------------------------------\n')
            f.write('Run parameters:\n')
            for key, val in gotm_args.items():
                f.write('    {:s} = {!s}\n'.format(key,val))
            f.write('--------------------------------------------------------------\n')
            f.write('Run statistics:\n')
            f.write('Elapsed: {:.2f} seconds.\n'.format(stat['elapsed']))
            f.write('--------------------------------------------------------------\n')
            f.write('Data statisitics:\n')
            with Dataset(os.path.join(local_folder,gotm_args['out_fn']+'.nc'),'r') as ds:
                sst = ds['sst'][:]
                time = ds['time']
                stat.update(sst_mean = sst.mean(),
                            sst_max = sst.max(),
                            sst_time_max = num2date(time[sst.argmax()],time.units),
                            sst_min = sst.min(),
                            sst_time_min = num2date(time[sst.argmin()],time.units))
                f.write('   SST:\n')
                f.write('      Mean: {sst_mean:.4g}\n'.format(**stat))
                f.write('      Max: {sst_max:.4g} at {sst_time_max!s}\n'.format(**stat))
                f.write('      Min: {sst_min:.4g} at {sst_time_min!s}\n'.format(**stat))
            f.write('--------------------------------------------------------------\n')
    except:
        raise

    if plotvars:
        from os.path import join
        from netCDF4 import num2date
        from matplotlib.pyplot import subplots
         
        assert isinstance(plotvars,list)
        ds = Dataset(out_fn+'.nc','r')
        time = num2date(ds['time'][:],ds['time'].units)

        # Read in data for plotting.
        var = dict()
        for varname in plotvars:
            # Some checking
            assert varname in ds.variables, 'Invalid variable specified: {!s}'.format(varname)
            assert len(time) == ds[varname].shape[0], 'Time dimension of variable: {!s} does not match with the time vector.'.format(varname)
            if len(ds[varname].shape) != 3:
                print('Skipping the variable: {!s} that depends on depth (for now...)'.format(varaname))
                continue

            # Now assuming we only plot against time.
            var[varname] = ds[varname][:,0,0]

        fig, axes = subplots(len(var),1,sharex=True)
        for i,(name, val) in enumerate(var.items()):
            ax = axes[i]
            ax.plot(time,val,label=name)
            ax.set_title(name)
            ax.grid('on')
        fig.autofmt_xdate()
        return stat, var
    else:
        return stat
